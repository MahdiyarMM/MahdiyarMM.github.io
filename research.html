<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <!-- SEO Meta Tags -->
  <title>Research - Mahdiyar Molahasani | AI & Computer Vision Publications</title>
  <meta name="description" content="Research publications by Mahdiyar Molahasani in AI, computer vision, federated learning, and domain generalization. 17+ papers in top venues like ICCV, AAAI, and NeurIPS.">
  <meta name="keywords" content="research, publications, AI, machine learning, computer vision, federated learning, domain generalization, ICCV, AAAI, NeurIPS">
  <meta name="author" content="Mahdiyar Molahasani">
  
  <!-- Open Graph Meta Tags -->
  <meta property="og:title" content="Research - Mahdiyar Molahasani">
  <meta property="og:description" content="Research publications in AI, computer vision, and machine learning. 17+ papers in top-tier conferences.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://www.molahasani.ca/research">
  <meta property="og:image" content="https://www.molahasani.ca/images/me2.jpg">
  
  <!-- Favicon -->
  <link rel="icon" type="image/png" href="images/icon.png">
  <link rel="apple-touch-icon" href="images/icon.png">
  
  <!-- PWA Manifest -->
  <link rel="manifest" href="manifest.json">
  
  <!-- Theme Color -->
  <meta name="theme-color" content="#ffffff">
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
  
  <!-- Stylesheets -->
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="styles/modern.css">
  
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-133321224-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-133321224-1');
  </script>
<style>
@media (max-width: 768px) {
  .paper-info {
    display: flex;
    flex-direction: column;
    align-items: center;
    text-align: center;
  }

  .paper-info td {
    width: 100%;
    display: block;
    padding: 10px 0;
  }

  .paper-info td:first-child {
    order: -1;
  }

  .paper-info img {
    width: 100%;  /* Keeps image within the screen */
    max-width: 600px; /* Adjust max size for better fit */
    height: auto;
    display: block;
    margin: 0 auto;
    object-fit: contain; /* Prevents cropping */
    transform: scale(1.3);
  }
}
	
  .header {
    position: fixed;
    top: 0;
    width: 100%;
    background-color: #f8f8f8;
    border-bottom: 1px solid #ddd;
    z-index: 1000;
  }

  .header .header-content {
    max-width: 800px;
    margin: 0 auto;
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 10px 20px;
  }

  .header .brand {
    font-size: 1.5em;
    font-weight: bold;
    color: #333;
    text-decoration: none;
  }

  .header .brand:hover {
    color: #0073e6;
  }

  .header a {
    text-decoration: none;
    font-size: 1.2em;
    color: #333;
    font-weight: bold;
    margin-left: 15px;
  }

  .header a:hover {
    color: #0073e6;
  }

    .content-container {
      position: relative;
      padding: 80px 20px 20px; /* Adjusted padding to account for fixed header */
      background: linear-gradient(to left, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 35%, rgba(255, 255, 255, 1) 65%, rgba(255, 255, 255, 0) 100%);
      max-width: 800px;
      margin: 0 auto;
    }
    img {
      transition: transform 0.3s;
    }

    img:hover {
      transform: scale(1.1);
    }
 </style>
  <style>
    #particles-js {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
    }
    .body-background {
      position: relative;
      background: linear-gradient(to left, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 35%, rgba(255, 255, 255, 1) 65%, rgba(255, 255, 255, 0) 100%);
      width: 100%;
    }
  </style>
</head>

<body class="research-page">
  <div id="particles-js"></div>
  
  <!-- Dark Mode Toggle -->
  <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode" title="Toggle dark mode">
    <i class="fas fa-moon" id="theme-icon"></i>
  </button>
  
  <header class="header" role="banner">
    <div class="header-content">
      <a href="https://www.molahasani.ca/" class="brand" aria-label="Mahdiyar Molahasani - Home">Mahdiyar Molahasani</a>
      <nav role="navigation" aria-label="Main navigation">
        <a href="https://www.molahasani.ca/">Home</a>
        <a href="https://www.molahasani.ca/research" aria-current="page">Research</a>
        <a href="https://www.molahasani.ca/cv">CV</a>
      </nav>
    </div>
  </header>
<div class="body-background">	
<div class="content-container">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr style="padding:0px">
  <td style="padding:0px">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">


        </tr>

		

	      
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
        <td style="padding:20px;width:100%;vertical-align:middle; text-align: center;">
		<h1>Research</h1>
            <p class="research-intro" align="justify" style="margin-bottom: 30px;">
                Welcome to the forefront of <span class="highlight">cutting-edge AI research</span>! My work bridges theory and practice in artificial intelligence, focusing on solving real-world challenges with innovative solutions. With over <span class="number">500</span> citations and impactful contributions presented at top-tier conferences like <span class="highlight">ICCV</span>, <span class="highlight">AAAI</span>, <span class="highlight">NeurIPS</span>, and <span class="highlight">ICASSP</span>, I specialize in <span class="highlight">federated learning</span>, <span class="highlight">domain generalization</span>, <span class="highlight">continual learning</span>, and <span class="highlight">computer vision</span>. From groundbreaking methods like <span class="highlight">FedGaLA</span> for privacy-preserving federated learning to pioneering frameworks for long-tailed recognition and out-of-distribution generalization, my research aims to create scalable, fair, and practical AI systems that empower diverse applications, from healthcare to astronomy. Let's advance the boundaries of AI together!
            </p>
            <div id="scholar-metrics" style="background-color: #f0f0f0; border-radius: 10px; display: inline-block; padding: 10px; margin: auto;  margin-bottom: 20px;">
                Citations: <span id="citation-count">0</span> | H-Index: <span id="h-index">0</span> | i10-Index: <span id="i10-index">0</span>
            </div>
              <script>
              async function loadScholarData() {
                  const response = await fetch("scholar_data.json");
                  const data = await response.json();

                  const duration = 2000;
                  const startTime = new Date().getTime();

                  function countUp() {
                      const currentTime = new Date().getTime();
                      const elapsed = currentTime - startTime;
                      const progress = Math.min(elapsed / duration, 1);

                      document.getElementById("citation-count").innerText = Math.round(data.citations * progress);
                      document.getElementById("h-index").innerText = Math.round(data.h_index * progress);
                      document.getElementById("i10-index").innerText = Math.round(data.i10_index * progress);

                      if (progress < 1) {
                          requestAnimationFrame(countUp);
                      }
                  }

                  countUp();
              }

              loadScholarData();
              </script>
		
	<p style="text-align:center; font-size: 24px; color: black;">
  <a href="mailto:m.molahasani@queensu.ca" style="color: DimGrey;"><i class="fas fa-envelope fa-2x"></i></a> &nbsp;·&nbsp;
  <a href="https://www.linkedin.com/in/m-molahasani/" style="color: DimGrey;"><i class="fab fa-linkedin fa-2x"></i></a> &nbsp;·&nbsp;
  <a href="https://scholar.google.com/citations?user=cXDt3NQAAAAJ&hl=en" style="color: DimGrey;"><i class="fas fa-graduation-cap fa-2x"></i></a> &nbsp;·&nbsp;
  <a href="https://github.com/MahdiyarMM" style="color: DimGrey;"><i class="fab fa-github fa-2x"></i></a> &nbsp;·&nbsp;
  <a href="https://mahdiyarmm.github.io/cv" style="color: DimGrey;"><i class="fas fa-file-alt fa-2x"></i></a>
</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


	<tr class="paper-info" style="margin-bottom: 30px;">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <img src="images/PRISM_cover_sqr.png" alt="PRISM" width="160" height="160">
	    </td>
	    <td width="75%" valign="middle">
	        <a href="https://arxiv.org/pdf/2507.08979">
	            <h3 class="paper-title">PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided Embedding Projection</h3>
	        </a>
	        <br>
	        <div class="authors"><strong>Mahdiyar Molahasani</strong><sup>*</sup>, Azadeh Motamedi<sup>*</sup>, Michael Greenspan, Il-Min Kim, Ali Etemad</div>
	        <br>
	        <a href="https://github.com/MahdiyarMM/PRISM" class="code-link">Code</a>
	        <p>
	            <div class="venue"><em>International Conference on Computer Vision (ICCV)</em>, July 2025</div>
	        </p>
	        <p class="paper-description" align="justify">
	            PRISM introduces a <span class="highlight">data-free</span>, <span class="highlight">task-agnostic</span> debiasing framework for <span class="highlight">VLMs</span>. It first leverages an <span class="highlight">LLM</span> to generate bias-aware scene descriptions from simple class prompts, then learns a linear projection of the <span class="highlight">CLIP</span> embedding space via a novel <span class="highlight">Latent-space Debiasing</span> loss that enforces intra-class invariance and inter-class separability. 
	    </td>
	</tr>

		

	<tr class="paper-info" style="margin-bottom: 30px;">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <img src="images/FedGaLA_nb.jpg" alt="clean-usnob" width="160" height="160">
	    </td>
	    <td width="75%" valign="middle">
	        <a href="https://arxiv.org/pdf/2405.16304">
	            <h3 class="paper-title">Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients</h3>
	        </a>
	        <br>
	        <div class="authors">Farhad Pourpanah<sup>*</sup>, <strong>Mahdiyar Molahasani</strong><sup>*</sup>, Milad Soltany<sup>*</sup>, Ali Etemad, Michael Greenspan</div>
	        <br>
		<a href="https://github.com/MahdiyarMM/FedGaLA" class="code-link">Code</a>
	        <p>
	            <div class="venue"><em>39th AAAI Conference on Artificial Intelligence. AAAI</em>, 2025</div>
		 <br>
		    <div class="venue"><em>NeurIPS Workshop on Mathematics of Modern Machine Learning (M3L)</em>, 2024</div>
	        </p>
		    
	        <p class="paper-description" align="justify">
		We introduced the novel problem of <span class="highlight">unsupervised federated domain generalization</span> and proposed <span class="highlight">FedGaLA</span>, a method that improves model generalization across unseen domains by aligning gradients at both the client and server levels. This work is grounded in a theoretical framework that links <span class="highlight">domain shift</span> to <span class="highlight">gradient alignment</span>. FedGaLA achieves <span class="highlight">state-of-the-art</span> performance on several domain generalization benchmarks.	    </td>
		</tr>

	<tr class="paper-info" style="margin-bottom: 30px;">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <img src="images/fedsb_nob.png" alt="clean-usnob" width="160" height="160">
	    </td>
	    <td width="75%" valign="middle">
	        <a href="https://arxiv.org/pdf/2412.11408">
	            <h3 class="paper-title">Federated Domain Generalization With Label Smoothing and Balanced Decentralized Training</h3>
	        </a>
	        <br>
	        <div class="authors">Milad Soltany<sup>*</sup>, Farhad Pourpanah<sup>*</sup>, <strong>Mahdiyar Molahasani</strong><sup>*</sup>, Michael Greenspan, Ali Etemad</div>
	        <br>
		<a href="https://github.com/miladsoltany/FedSB" class="code-link">Code</a>
	        <p>
	        <div class="venue"><em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2025</div>
	        </p>
		    
	        <p class="paper-description" align="justify">
		We propose <span class="highlight">FedSB</span>, a method for <span class="highlight">federated domain generalization</span> that improves model robustness across diverse domains using <span class="highlight">label smoothing</span> to reduce local overconfidence and a <span class="highlight">balanced training mechanism</span> to mitigate <span class="highlight">data heterogeneity</span>. 		
		</tr>

		
	<tr class="paper-info" style="margin-bottom: 30px;">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <img src="images/cltr.png" alt="clean-usnob" width="160" height="160">
	    </td>
	    <td width="75%" valign="middle">
	        <a href="https://openreview.net/pdf?id=IfyZSIxcoM">
	            <h3 class="paper-title">Continual Learning for Long-Tailed Recognition</h3>
	        </a>
	        <br>
	        <div class="authors"><strong>Mahdiyar Molahasani</strong>, Ali Etemad, Michael Greenspan</div>
	        <br>
	        <a href="https://neurips.cc/virtual/2023/81717" class="code-link">Poster</a>
	        <p>
	            <div class="venue"><em>NeurIPS Workshop on Mathematics of Modern Machine Learning (M3L)</em>, 2023</div>
	        </p>
	        <p class="paper-description" align="justify">
		This work presents a theoretical framework for addressing <span class="highlight">long-tailed recognition (LTR)</span> through <span class="highlight">continual learning (CL)</span>, where models are trained sequentially on data subsets to balance performance across <span class="highlight">head (frequent)</span> and <span class="highlight">tail (rare)</span> classes. By proving bounds on <span class="highlight">model weight updates</span> and demonstrating CL's effectiveness on benchmark datasets, the authors show that CL can significantly improve LTR performance, offering a unified approach that aligns both theoretical insights and practical results in machine learning.	    </td>
		</tr>
		
	<tr class="paper-info" style="margin-bottom: 30px;">
	    <td style="padding:20px;width:25%;vertical-align:middle">
	        <img src="images/citpersons.jpg" alt="clean-usnob" width="160" height="160">
	    </td>
	    <td width="75%" valign="middle">
	        <a href="https://ieeexplore.ieee.org/abstract/document/10222758?casa_token=n5mCxJDHWFkAAAAA:ESZlydvgtjzSOZ3rM7qoLpmoiZsw4G7qanstti_J08rj2ubfIBvSeDRsVGQlXLHmlYGUFwhczM8">
	            <h3 class="paper-title">Continual Learning for Out-of-Distribution Generalization in Pedestrian Detection</h3>
	        </a>
	        <br>
	        <div class="authors"><strong>Mahdiyar Molahasani</strong>, Ali Etemad, Michael Greenspan</div>
	        <br>
	        <a href="https://arxiv.org/abs/2306.15117" class="code-link">arXiv</a>/<a href="https://github.com/MahdiyarMM/Continual-pedestrian-detection" class="code-link">Code</a>
	        <p>
	            <div class="venue"><em>International Conference of Image Processing (ICIP)</em>, 2023</div>
	        </p>
	        <p class="paper-description" align="justify">
			This study introduces the first <span class="highlight">continual learning</span> approach for <span class="highlight">pedestrian detection</span> that can effectively address <span class="highlight">distribution shift</span>, a common issue in prior works. We proposed modified <span class="highlight">Elastic Weight Consolidation</span> for <span class="highlight">object detection networks</span>, enabling the model to maintain its performance across different datasets and significantly improve the miss rate on <span class="highlight">CrowdHuman</span> and <span class="highlight">CityPersons</span> datasets by mitigating <span class="highlight">catastrophic forgetting</span>.	    </td>
		</tr>


	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crowd.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/9747776">
                <h3 class="paper-title">Multi-scale Multi-task Crowd Counting</h3>
              </a>
              <br>
              <div class="authors">Mohsen Zand, Haleh Damirchi, Andrew Farley, <strong>Mahdiyar Molahasani</strong>, Michael Greenspan, Ali Etemad</div>
	      <br>
	      <a href="https://arxiv.org/abs/2202.09942" class="code-link">arXiv</a>/<a href="https://github.com/MahdiyarMM/crowd_counting" class="code-link">Code</a>
	      <p>
              <div class="venue"><em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2022</div>
	      </p>
              <p class="paper-description" align="justify">A <span class="highlight">multi-scale crowd counting</span> and <span class="highlight">localization platform</span> is proposed in this work. This novel architecture alongside the <span class="highlight">multi-scale multi-task loss function</span> has demonstrated promising performance.</p>
	    </td>
          </tr>
	
	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/msg.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/article/10.1007/s11042-020-09489-y">
                <h3 class="paper-title">MSG-Caps GAN for Face Super-Resolution</h3>
              </a>
              <br>
              <div class="authors"><strong>Mahdiyar Molahasani</strong>, Seok-bum Ko</div>
	      <br>
	      <a href="https://ieeexplore.ieee.org/abstract/document/9051244" class="code-link">Conference</a>/<a href="https://github.com/MahdiyarMM/MSG-CapsGAN" class="code-link">Code</a>
	      <p>
              <div class="venue"><em>International Conference on Electronics, Information, and Communication (ICEIC)</em>, 2020</div>
	      <br>
	      <div class="venue"><em>Multimedia Tools and Applications</em>, 2020</div>
	      </p>
              <p class="paper-description" align="justify">We proposed the first <span class="highlight">Multi-scale gradient capsule GAN</span> and utilized it for <span class="highlight">face super-resolution</span>. This model outperformed <span class="highlight">state-of-the-art</span> face super-resolution models.</p>
            </td>
          </tr>


	
	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/covid.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/article/10.1007/s11042-022-12156-z">
                <h3 class="paper-title">COVID-CXNet: Detecting COVID-19 in Frontal Chest X-ray Images</h3>
              </a>
              <br>
              <div class="authors">Arman Haghanifar, <strong>Mahdiyar Molahasani</strong>, Younhee Choi, S Deivalakshmi, Seok-bum Ko</div>
	      <br>
	      <a href="https://arxiv.org/abs/2006.13807" class="code-link">arXiv</a>/<a href="https://github.com/MahdiyarMM/COVID-CXNet" class="code-link">Code</a>
	      <p>
	      <div class="venue"><em>Multimedia Tools and Applications</em>, 2021</div>
	      </p>
              <p class="paper-description" align="justify">In this work, the largest publicly available dataset for <span class="highlight">COVID-19</span> is collected and a powerful <span class="highlight">COVID-19 detection model</span> based on <span class="highlight">CheXNet</span> is proposed. This model can detect <span class="highlight">COVID19</span> accurately using <span class="highlight">meaningful features</span></p>
            </td>
          </tr>




          
	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/prostate.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/article/10.1007/s11042-020-09489-y">
                <h3 class="paper-title">High-scale Prostate MRI Super-Resolution with MSG-CapsGAN</h3>
              </a>
              <br>
              <div class="authors"><strong>Mahdiyar Molahasani</strong>, Younhee Choi, S Deivalakshmi, Seok-bum Ko</div>
	      <br>
	      <p>
	      <div class="venue"><em>Multimedia Tools and Applications</em>, 2021</div>
	      </p>
              <p class="paper-description" align="justify">One of the first attempts for <span class="highlight">high-scale super-resolution (8x)</span> in <span class="highlight">biomedical domain</span>. <span class="highlight">MSG-CapsGAN</span> shows promising results in the <span class="highlight">medical domain</span> as well.</p>
            </td>
          </tr>


	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tooth.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/article/10.1007/s11042-023-14435-9">
                <h3 class="paper-title">Automated Tooth Extraction and Caries Detection</h3>
              </a>
              <br>
              <div class="authors">Arman Haghanifar, <strong>Mahdiyar Molahasani</strong>, Seok-bum Ko</div>
	      <br>
	      <a href="https://arxiv.org/abs/2012.13666" class="code-link">arXiv</a>/<a href="https://ieeexplore.ieee.org/abstract/document/9180937" class="code-link">Conference</a>/<a href="https://github.com/MahdiyarMM/Teeth-Extraction" class="code-link">Code (extraction)</a>/<a href="https://github.com/MahdiyarMM/Dental-Caries-Classification" class="code-link">Code (detection)</a>
              <p>
              <div class="venue"><em>IEEE International Symposium on Circuits and Systems (ISCAS)</em>, 2020</div>
	      <br>
	      <div class="venue"><em>Multimedia Tools and Applications</em>, 2023</div>
	      </p>
              <p class="paper-description" align="justify">A fully automated <span class="highlight">tooth extraction model</span> is implemented using a <span class="highlight">genetic algorithm</span>. A <span class="highlight">multi-feature extraction model</span> with a <span class="highlight">capsule classifier</span> is developed for <span class="highlight">caries detection</span>.</p>
            </td>
          </tr>	      

	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/astro.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13097/1309783/AI-powered-low-order-focal-plane-wavefront-sensing-in-infrared/10.1117/12.3020402.short#_=_">
                <h3 class="paper-title">AI-powered Low-order Focal Plane Wavefront Sensing in Infrared</h3>
              </a>
              <br>
              <div class="authors">Mojtaba Taheri, <strong>Mahdiyar Molahasani</strong>, Sam Ragland, Benoit Neichel, Peter Wizinowich</div>
	      <br>
	      <p>
	      <div class="venue"><em>Adaptive Optics Systems IX</em>, 2024</div>
	      </p>
              <p class="paper-description" align="justify">We propose an <span class="highlight">AI-powered FPWFS</span> method specifically for <span class="highlight">low-order mode estimation</span> in <span class="highlight">infrared wavelengths</span>. Our approach is trained on <span class="highlight">simulated data</span> and validated on on-telescope data collected from the <span class="highlight">Keck I adaptive optic (K1AO)</span> bench calibration source in <span class="highlight">K-band</span>. This study paves the way for more compact, efficient, and high-performing <span class="highlight">AO systems</span> for <span class="highlight">astronomical observations</span>.</p>
            </td>
          </tr> 
	  

	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/memristor.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0026269220300094">
                <h3 class="paper-title">Hybrid CMOS/Memristor Crossbar Implementation of Recurrent Neural Networks</h3>
              </a>
              <br>
              <div class="authors"><strong>Mahdiyar Molahasani</strong>, Jafar Shamsi, S. B. Shokouhi, Seok-bum Ko</div>
	      <br>
	      <a href="https://link.springer.com/article/10.1007/s10470-020-01720-y" class="code-link">Hopfield</a>/<a href="https://www.sciencedirect.com/science/article/abs/pii/S0026269220300094" class="code-link">BAM</a>/<a href="https://github.com/MahdiyarMM/Memristive-Associative-Memory" class="code-link">Code</a>
              <p>
              <div class="venue"><em>Analog Integrated Circuits and Signal Processing</em>, 2021</div>
	      <br>
	      <div class="venue"><em>Microelectronics Journal</em>, 2020</div>
	      </p>
              <p class="paper-description" align="justify">An efficient and scalable <span class="highlight">transistor-level implementation</span> of two different <span class="highlight">recurrent neural networks</span> is proposed using a <span class="highlight">memristor crossbar array</span>.</p>
            </td>
          </tr>	 


	 <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/Anomaly.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8985068">
                <h3 class="paper-title">Anomaly Prediction in 5G Network</h3>
              </a>
              <br>
              <div class="authors">Ramin Sharifi, <strong>Mahdiyar Molahasani</strong>, Vahid Tabataba Vakili</div>
	      <br>
	      <p>
	      <div class="venue"><em>IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM)</em>, 2019</div>
	      </p>
              <p class="paper-description" align="justify">An <span class="highlight">LSTM network</span> is utilized for <span class="highlight">user activity prediction</span> in <span class="highlight">5G networks</span>. The proposed model can accurately predict <span class="highlight">anomalies</span> up to one hour in advance.</p>
	</td>
          </tr>


	  <tr class="paper-info" style="margin-bottom: 30px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/erosion.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://asmedigitalcollection.asme.org/FPST/proceedings-abstract/FPMC2021/V001T01A058/1129254">
                <h3 class="paper-title">Erosion Detection in Hydraulic Tubes and Hoses Using GRU</h3>
              </a>
              <br>
              <div class="authors">Elnaz Etminan, <strong>Mahdiyar Molahasani</strong>, Seok-bum Ko, Travis Wiens</div>
	      <br>
	      <p>
	      <div class="venue"><em>Fluid Power Systems Technology, American Society of Mechanical Engineers</em>, 2021</div>
	      </p>
             <p class="paper-description" align="justify">The characteristics of the <span class="highlight">eroded area</span> in the pipe are extracted from the <span class="highlight">pressure response</span> using a <span class="highlight">GRU network</span>. This work represents the first <span class="highlight">erosion detection system</span> leveraging <span class="highlight">deep learning</span>.</p>            </td>
          </tr>



        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <p>
		© 2025 Mahdiyar Molahasani. All rights reserved.
              </p>
            </td>
          </tr>			
        </tbody></table>
      </td>
    </tr>
  </table>


<script>
  document.addEventListener("DOMContentLoaded", function () {
    const paperInfoElements = document.querySelectorAll(".paper-info");

    const observer = new IntersectionObserver(
      (entries) => {
        entries.forEach((entry) => {
          if (entry.isIntersecting) {
            entry.target.classList.add("visible");
          } else {
            entry.target.classList.remove("visible");
          }
        });
      },
      {
        rootMargin: "0px 0px -20% 0px",
        threshold: 0,
      }
    );

    paperInfoElements.forEach((element) => {
      observer.observe(element);
    });
  });
</script>
</div>
</div>
  <script src="particles.js"></script>
  <script src="js/app.js"></script>
  <script src="js/modern.js"></script>
</body>

</html>
